{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "eb34c6a0-8583-4ed3-a55f-ce17f9d74ea8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Securing access to External Tables / Files with Unity Catalog\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/external/uc-external-location-global.png?raw=true\" style=\"float:right; margin-left:10px\" width=\"600\"/>\n",
    "\n",
    "By default, Unity Catalog will create managed tables in your primary storage, providing a secured table access for all your users.\n",
    "\n",
    "In addition to these managed tables, you can manage access to External tables and files, located in another cloud storage (S3/ADLS/GCS). \n",
    "\n",
    "This give you capabilities to ensure a full data governance, storing your main tables in the managed catalog/storage while ensuring secure access for for specific cloud storage.\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=governance&org_id=1459955580342996&notebook=%2FAWS-Securing-data-on-external-locations&demo_name=uc-02-external-location&event=VIEW&path=%2F_dbdemos%2Fgovernance%2Fuc-02-external-location%2FAWS-Securing-data-on-external-locations&version=1&user_hash=e83debf9c2fbbbade446ffcd4d65ccfdeb93bd7927314dd02f530d8731ff8498\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ace4a6b4-9a18-4172-8d87-b4d04eea5600",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SETUP - Specify the bucket to use as external location"
    }
   },
   "outputs": [],
   "source": [
    "#TODO= replace with the URL of the bucket you want to use for your external location:\n",
    "# s3://demonhid15-rootbucket-sm/external_vol/\n",
    "external_bucket_url = \"s3://demonhid15-rootbucket-sm/external_source_ext/\"\n",
    "dbutils.widgets.text(\"external_bucket_url\", external_bucket_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "6cf3735c-9ab9-414a-9af8-e101da2b66e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Working with External Locations\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/external/uc-external-location.png?raw=true\" style=\"float:right; margin-left:10px\" width=\"800\"/>\n",
    "\n",
    "\n",
    "Accessing external cloud storage is easily done using `External locations`.\n",
    "\n",
    "This can be done using 3 simple SQL command:\n",
    "\n",
    "\n",
    "1. First, create a Storage credential. It'll contain the IAM role/SP required to access your cloud storage\n",
    "1. Create an External location using your Storage credential. It can be any cloud location (a sub folder)\n",
    "1. Finally, Grant permissions to your users to access this Storage Credential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "26011ba2-f338-4842-ac8c-4322ecb9e597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1/ Create the STORAGE CREDENTIAL\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/external/uc-external-location-1.png?raw=true\" style=\"float:right; margin-left:10px\" width=\"700px\"/>\n",
    "\n",
    "The first step is to create the `STORAGE CREDENTIAL`.\n",
    "\n",
    "To do that, we'll use Databricks Unity Catalog UI:\n",
    "\n",
    "1. Open the Data Explorer in DBSQL\n",
    "1. Select the \"Storage Credential\" menu\n",
    "1. Click on \"Create Credential\"\n",
    "1. Fill your credential information: the name and IAM role you will be using\n",
    "\n",
    "Because you need to be ADMIN, this step has been created for you.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/external/uc-external-location-cred.png?raw=true\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38fb3207-708a-4443-bdf8-cdd437672244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- For our demo, let's make sure all users can alter this storage credential:\n",
    "-- ALTER STORAGE CREDENTIAL `field_demos_credential`  OWNER TO `account users`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79af62df-ec16-495d-b621-c0eac0271f85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW STORAGE CREDENTIALS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ccb3379-0f9b-4d9c-bc28-58db8ce40da8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DESCRIBE STORAGE CREDENTIAL `field_demos_credential`\n",
    "DESCRIBE STORAGE CREDENTIAL `uc-upgrade-cred`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "4e8f4d61-4b13-4419-84c0-a9e12e65f6c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2/ Create the EXTERNAL LOCATION\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/external/uc-external-location-2.png?raw=true\" style=\"float:right; margin-left:10px\" width=\"700px\"/>\n",
    "\n",
    "We'll then create our `EXTERNAL LOCATION` using the following path:<br/>\n",
    "`s3a://databricks-e2demofieldengwest/external_location/`\n",
    "\n",
    "Note that you need to be Account Admin to do that, it'll fail with a permission error if you are not. But don't worry, the external location has been created for you.\n",
    "\n",
    "You can also update your location using SQL operations:\n",
    "<br/>\n",
    "```ALTER EXTERNAL LOCATION `xxxx`  RENAME TO `yyyy`; ```<br/>\n",
    "```DROP EXTERNAL LOCATION IF EXISTS `xxxx`; ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3604f4e0-a2d1-4173-b2cd-d063f6ab2f05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(external_bucket_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ef87580-89c9-4711-9675-a5eef0e170d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Note: you need to be account ADMIN to run this and create the external location.\n",
    "CREATE EXTERNAL LOCATION IF NOT EXISTS `field_demos_external_location`\n",
    "  URL \"s3://demonhid15-rootbucket-sm/customer_a_ext/\"\n",
    "  WITH (CREDENTIAL `uc-upgrade-cred`)\n",
    "  COMMENT 'External Location for demos' ;\n",
    "\n",
    "\n",
    "-- let's make everyone owner for the demo to be able to change the permissions easily. DO NOT do that for real usage.\n",
    "ALTER EXTERNAL LOCATION `field_demos_external_location`  OWNER TO `account users`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3b0a6c9-e7b3-459e-a302-a98808b9193b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW EXTERNAL LOCATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b04dfd7-610c-4c55-9603-a69f67362dcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE EXTERNAL LOCATION `field_demos_external_location`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "a1abcd4f-05f1-4385-89f3-523f1c561c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3/ GRANT permissions on the external location\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/external/uc-external-location-3.png?raw=true\" style=\"float:right; margin-left:10px\" width=\"700px\"/>\n",
    "\n",
    "All we have to do is now GRANT permission to our users or group of users. In our demo we'll grant access to all our users using `account users`\n",
    "\n",
    "We can set multiple permissions:\n",
    "\n",
    "1. READ FILES to be able to access the data\n",
    "1. WRITE FILES to be able to write data\n",
    "1. CREATE TABLE to create external table using this location\n",
    "\n",
    "To revoke your permissions, you can use ```REVOKE WRITE FILES ON EXTERNAL LOCATION `field_demos_external_location` FROM `account users`;```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63976d38-a4e0-4e56-93bf-6bb9a53ca792",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "GRANT READ FILES, WRITE FILES ON EXTERNAL LOCATION `field_demos_external_location` TO `account users`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6eca7f7c-7ed4-4bd6-b159-884af1bc0f9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Accessing the data\n",
    "\n",
    "That's all we have to do! Our users can now access the folder in SQL or python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c99cb21-066e-40e8-8a46-0d022c16de96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Make sure you set this to your own external location  \n",
    "LIST 's3://demonhid15-rootbucket-sm/external_source_ext/'\n",
    "    \n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b55ddc8a-431a-4c17-aabe-c2469c1b4e1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "we can also write data using SQL or Python API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5bd777f-5732-45eb-9989-c6a1f7bedc62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(\"UC\", \"is awesome\"), (\"Delta Sharing\", \"is magic\")])\n",
    "df.write.mode('overwrite').format('csv').save(f'{external_bucket_url}/test_write_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "821f7661-6b20-41c2-96c3-d39953d1f2bb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading the data using pyspark API:"
    }
   },
   "outputs": [],
   "source": [
    "spark.read.csv(f'{external_bucket_url}/test_write_table').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "997bd6f8-0385-4782-a3a7-c7e52f85f593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Create External Table with Huge Data\n",
    "- Create External Table with Huge Data with Partition\n",
    "- Create External Table with Huge Data with Liquid Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df2b8c15-f7d4-4bc2-921d-ec5836d6e1b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/databricks-datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "163b44fb-d024-437f-8ee1-b011c666e9b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"dbfs:/databricks-datasets/flights/departuredelays.csv\", header=True, inferSchema=True)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05b59834-5a7d-4dae-b6f6-3ddd9d3552db",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read Data"
    }
   },
   "outputs": [],
   "source": [
    "external_bucket_url = \"s3://demonhid15-rootbucket-sm/customer_a_ext\"\n",
    "\n",
    "# 2. Load the source table into a DataFrame\n",
    "print(\"Loading samples.tpch.lineitem dataset...\")\n",
    "try:\n",
    "    lineitem_df = spark.table(\"samples.tpch.lineitem\")\n",
    "    print(f\"Dataset loaded successfully. Column count: {len(lineitem_df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading table: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de30bd39-c2c3-4973-beb8-66962edf7422",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write Delta"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Define the full output path\n",
    "output_path = f\"{external_bucket_url}/lineitem_delta_export\"\n",
    "\n",
    "# 4. Write the DataFrame to the external location in CSV format\n",
    "print(f\"Writing data to Delta format at: {output_path}\")\n",
    "\n",
    "lineitem_df.write.mode('overwrite').format('delta').save(output_path)\n",
    "\n",
    "print(\"---\")\n",
    "print(\"Success! The Lineitem data has been exported.\")\n",
    "print(f\"Check the following directory for the CSV output part files: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a76dc5dc-d940-4138-afbe-22fe150aabd5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write Delta Partitioned"
    }
   },
   "outputs": [],
   "source": [
    "partition_column = \"l_shipdate\"\n",
    "output_path = f\"{external_bucket_url}/lineitem_delta_partitioned_export\"\n",
    "print(f\"\\nWriting data to DELTA format, partitioned by '{partition_column}', at: {output_path}\")\n",
    "\n",
    "# .partitionBy(partition_column): Crucial for creating physical folders based on the column values\n",
    "lineitem_df.write \\\n",
    "    .mode('overwrite') \\\n",
    "    .format('delta') \\\n",
    "    .partitionBy(partition_column) \\\n",
    "    .save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a4dca56-5a15-4400-a359-581d6ace1f55",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create External Delta Table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog demonhid15;\n",
    "use schema customer_a;\n",
    "CREATE TABLE IF NOT EXISTS demonhid15.customer_a.lineitem_delta_ext\n",
    "USING DELTA\n",
    "LOCATION 's3://demonhid15-rootbucket-sm/customer_a_ext/lineitem_delta_export';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9672344-0fdc-4226-b51e-30df7903d2e8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create External Delta Table on Partitioned"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog demonhid15;\n",
    "use schema customer_a;\n",
    "CREATE TABLE IF NOT EXISTS demonhid15.customer_a.lineitem_delta_partitioned_ext\n",
    "USING DELTA\n",
    "LOCATION 's3://demonhid15-rootbucket-sm/customer_a_ext/lineitem_delta_partitioned_export';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2294b28-bef0-4664-a273-1066576173e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) FROM demonhid15.customer_a.lineitem_delta_ext -- 29999795\n",
    "union all \n",
    "SELECT COUNT(*) FROM demonhid15.customer_a.lineitem_delta_partitioned_ext -- 29999795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f3e7c2-0a7f-42da-b7d3-1e124bcfcab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- SELECT COUNT(*) FROM demonhid15.customer_a.lineitem_delta_ext -- 29999795\n",
    "\n",
    "SELECT * FROM demonhid15.customer_a.lineitem_delta_partitioned_ext -- 29999795\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71ba8306-1239-46c7-a644-9fe417f6335b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[https://delta.io/blog/liquid-clustering/](https://delta.io/blog/liquid-clustering/)\n",
    "\n",
    "Liquid clustering gives you flexibility. With liquid clustering enabled, you can redefine your clustering columns without having to rewrite any existing data. This allows your data layout to evolve in parallel with changing query patterns.\n",
    "\n",
    "Note that liquid clustering is not compatible with partitioning and Z-ordering.\n",
    "\n",
    "\n",
    "[https://www.databricks.com/blog/introducing-predictive-optimization-statistics](https://www.databricks.com/blog/introducing-predictive-optimization-statistics)\n",
    "\n",
    "**This require UC Catalog**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24b8ed96-be30-47b3-b8a3-701e51031776",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6939092143447059,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "data-on-external-locations",
   "widgets": {
    "external_bucket_url": {
     "currentValue": "s3://demonhid15-rootbucket-sm/external_vol/",
     "nuid": "b082d08d-664a-433a-91ed-1ec80a180103",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "s3://demonhid15-rootbucket-sm/care_source_ext/",
      "label": null,
      "name": "external_bucket_url",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "s3://demonhid15-rootbucket-sm/care_source_ext/",
      "label": null,
      "name": "external_bucket_url",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
